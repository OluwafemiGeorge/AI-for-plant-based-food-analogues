# -*- coding: utf-8 -*-
"""Extended_sim (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vKEQe58TWn0DDXw8OcA0gqKxnXVi_Qab
"""

from google.colab import drive
drive.mount('/content/drive')

cd 'drive/MyDrive/Colab Notebooks'

import csv
!pip install rdkit-pypi
import time
import random
import sys
from pathlib import Path
import seaborn as sns

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
sns.set()
from rdkit import Chem
from rdkit import DataStructs
from rdkit.ML.Cluster import Butina
from rdkit.Chem import Draw
from rdkit.Chem import rdFingerprintGenerator
from rdkit.Chem.Draw import SimilarityMaps
from rdkit.Chem import AllChem
from rdkit.Chem import MACCSkeys
from statistics import mean

import time
start_time = time.time()
# read and Concatenate the csv's
df = pd.read_csv('single_functional_group.csv')
#df_2 = pd.read_csv('second.csv')
#df_3 = pd.concat([df_1, df_2])
# df = df.drop("code", axis = 1)

code = []
for i in range(len(df)):
  code.append("A{0}".format(i+1))
df['code'] = code
code=list(df['code'])
df = df.dropna()

df_foods = df.groupby("Name")
df = df_foods.get_group("Goat Milk")
Foods = df.Name.unique()

# proof and make a list of SMILES
df_smiles = df['SMILES']
c_smiles = []
total_invalid = 0
for ds in df_smiles:
    try:
        cs = Chem.CanonSmiles(ds)
        c_smiles.append(cs)
    except:
        total_invalid += 1
        print('Invalid SMILES:', ds)
print(total_invalid)

from statistics import mean
# make a list of mols
ms = [Chem.MolFromSmiles(x) for x in c_smiles]
mms = [k for k in c_smiles]
r=[]
for i in mms:
  mol=Chem.MolFromSmiles(i)
  maccs = MACCSkeys.GenMACCSKeys(mol)
  array = np.zeros((0,), dtype=np.int8)
  p_maccs= np.nonzero(maccs)
  q_maccs=np.array(p_maccs)
  w_maccs=q_maccs.size
  r.append(w_maccs)
df1 = pd.DataFrame({'nonzero':r})
 #make a list of mols
ms = [Chem.MolFromSmiles(x) for x in c_smiles]
mms = [k for k in c_smiles]
df1=list(df1['nonzero'])

# make a list of fingerprints (fp)
rdkit_gen = rdFingerprintGenerator.GetRDKitFPGenerator(maxPath=7)
fps_maccs = [MACCSkeys.GenMACCSKeys(x) for x in ms]
fps_m512 = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=512) for mol in ms]

# the list for the dataframe
ta, sim, bits, new_diff = [], [], [], []

from numpy.lib.index_tricks import s_

#for just 1st two
n_maccs = len(fps_maccs) # 1st two
#s = tanimoto coefficient
s_m512 = DataStructs.BulkTanimotoSimilarity(fps_m512[0], fps_m512[:] ) # +1 compare with the next to the last fp
for m in range(len(s_m512)):
    ta.append(code[:][m])
    sim.append(s_m512[m])
    new_diff.append(1 - s_m512[m])
bits = df1
print(len(ta), len(sim), len(new_diff), len(bits))

# build the dataframe and sort it}
d = {'target':ta, 'Similarity':sim, 'No_of_bits':bits, 'new_diff':new_diff}
df_final = pd.DataFrame(data=d)
df_final

df_final['Similarity']

# make a list of fingerprints (fp)
rdkit_gen = rdFingerprintGenerator.GetRDKitFPGenerator(maxPath=7)
fps_maccs = [MACCSkeys.GenMACCSKeys(x) for x in ms]
fps_m512 = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=512) for mol in ms]
fps_m1024 = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024) for mol in ms]
fps_m2048 = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048) for mol in ms]
fps_m4096 = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=4096) for mol in ms]
# list(map(int, str(num)))
big_matrix = [list(map(int, x.ToBitString())) for x in fps_m512]
print(big_matrix)
print(len(big_matrix[0]))

print(len(big_matrix[0]))

total_arr = []

for col in range(len(big_matrix[0])):
  total = 0
  for row in big_matrix:
    print(row)
    total += int(row[col])
  print(total)
  total_arr.append(total)
print(total_arr)

#Calculate Cn(k) 0<=k<=n
Cnk = {}
length = len(big_matrix)
for k in range(length + 1):
  Cnk[f"C{length}({k})"] = total_arr.count(k)
list_cnk = list(Cnk.values())
print(list_cnk)
print(Cnk)

#check that total_arr is the length of fingerprints
total_cnk = 0
for i in Cnk:
  total_cnk +=  Cnk[i]
print(total_cnk == len(total_arr))

#calculate Delta n(k) = |2k - n|
Dnk = {}
for k in range(length + 1):
  # D{length}({k})" = abs((2 * k) - length)
  Dnk[f"D{length}({k})"] = abs((2 * k) - length)
  #print(f"D{length}({k}) = {abs((2 * k) - length)}")
list_dnk = list(Dnk.values())
print(Dnk)

#concidence treshold Y = n mod 2
Y = length % 2
print(Y)

#classify Cn(k) in similarity counters
weight_function = []
classification = []
similarity_counter = []
for k in range(length + 1):
  if ((2 * k) - length) > Y:
    print(f"2 X {k} - {length} > {Y} --> C{length}({k}) is a 1-similarity counter")
    similarity_counter.append("1-similarity counter")
    print(f"fs(D{length}({k})) = {(abs((2 * k) - length)) / length}")
    weight_function.append(abs((2 * k) - length) / length)
    classification.append('sim')
  elif (length - (2* k) > Y):
    print(f"{length} - 2 X {k} > {Y} --> C{length}({k}) is a 0-similarity counter")
    similarity_counter.append("0-similarity counter")
    print(f"fs(D{length}({k})) = {(abs((2 * k) - length)) / length}")
    weight_function.append(abs((2 * k) - length) / length)
    classification.append('sim')
  elif (abs((2 * k) - length) <= Y):
    print(f"2 X {k} - {length} <= {Y} --> C{length}({k}) is a dissimilarity counter")
    similarity_counter.append("dissimilarity counter")
    print(f"fd(D{length}({k})) = {1 - (((abs((2 * k) - length)) - Y) / length)}")
    weight_function.append(1 - (((abs((2 * k) - length)) - Y) / length))
    classification.append('dissim')
print(weight_function)

table = {}
table['Cs'] = list_cnk
table['Ds'] = list_dnk
table['class'] = classification
table['weight_function'] = weight_function
df = pd.DataFrame.from_dict(table)
df['multiplication'] = df['Cs'] * df['weight_function']
df["similarity counter"] = similarity_counter
df

def add_sim_type(cls, similarity_counter):
  sim_sum = 0
  for i in range(len(df)):
    if df["class"][i] == cls and df["similarity counter"][i] == similarity_counter:
      sim_sum += df["weight_function"][i] * df["Cs"][i]
  return float(sim_sum)

#extended similarity using Jackard
SeSM_ls_wd = round((3* add_sim_type("sim", "1-similarity counter"))/(3*(add_sim_type("sim", "1-similarity counter") + add_sim_type("dissim", "dissimilarity counter"))), 9)
SeSM_ls_wd

def add_sim_type(cls, column):
  sim_sum = 0
  for i in range(len(df)):
    if df["class"][i] == cls:
      sim_sum += df[column][i]
  return float(sim_sum)

SeSM_ls_wd = round((add_sim_type("sim", "multiplication")/(add_sim_type("sim", "multiplication") + add_sim_type("dissim", "multiplication"))), 4)
SeSM_ls_wd

SeSM_ls_d = round((add_sim_type("sim", "multiplication")/(add_sim_type("sim", "Cs") + add_sim_type("dissim", "Cs"))), 4)
SeSM_ls_d